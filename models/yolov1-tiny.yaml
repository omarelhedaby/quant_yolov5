# Parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 0.2  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
#   - [30,61, 62,45, 59,119]  # P4/16
#   - [116,90, 156,198, 373,326]  # P5/32

weight_bit_width: 8
act_bit_width: 8

# YOLOv3-tiny backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, QuantConv, [16, 3, 1, None, weight_bit_width, act_bit_width]],  # 0
   [-1, 1, QuantMaxPool2d, [2, 2, 0]],  # 1-P1/2
   [-1, 1, QuantConv, [32, 3, 1, None, weight_bit_width, act_bit_width]],
   [-1, 1, QuantMaxPool2d, [2, 2, 0]],  # 3-P2/4
   [-1, 1, QuantConv, [64, 3, 1, None, weight_bit_width, act_bit_width]],
   [-1, 1, QuantMaxPool2d, [2, 2, 0]],  # 5-P3/8
   [-1, 1, QuantConv, [128, 3, 1, None, weight_bit_width, act_bit_width]],
   [-1, 1, QuantMaxPool2d, [2, 2, 0]],  # 7-P4/16
   [-1, 1, QuantConv, [256, 3, 1, None, weight_bit_width, act_bit_width]],
   [-1, 1, QuantMaxPool2d, [2, 2, 0]],  # 9-P5/32
   [-1, 1, QuantConv, [512, 3, 1, None, weight_bit_width, act_bit_width]],  # 10
  ]

# YOLOv3-tiny head
head:
  [[-1, 1, QuantConv, [1024, 3, 1, None, weight_bit_width, act_bit_width]],
   [-1, 1, QuantConv, [256, 1, 1, None, weight_bit_width, act_bit_width]],
   [-1, 1, QuantConv, [512, 3, 1, None, weight_bit_width, act_bit_width]],  # 13 (P5/32-large)
   [-1, 1, QuantSimpleConv, [(nc+5)*3, 3, 1, None, weight_bit_width, act_bit_width]], # 14
   
   [[14], 1, Detect, [nc, anchors, True, weight_bit_width]],  # Detect(P4, P5)
  ]