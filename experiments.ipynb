{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qr requirements.txt # install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "e8225db4-e61d-4640-8b1f-8bfce3331cea"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 1. Detect\n",
    "\n",
    "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
    "\n",
    "```shell\n",
    "python detect.py --source 0  # webcam\n",
    "                          img.jpg  # image\n",
    "                          vid.mp4  # video\n",
    "                          screen  # screenshot\n",
    "                          path/  # directory\n",
    "                         'path/*.jpg'  # glob\n",
    "                         'https://youtu.be/LNwODJXcvt4'  # YouTube\n",
    "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zR9ZbuQCH7FX",
    "outputId": "284ef04b-1596-412f-88f6-948828dd2b49"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
    "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkAzDWJ7cWTr"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 2. Validate\n",
    "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQPtK1QYVaD_",
    "outputId": "cf7d52f0-281c-4c96-a488-79f5908f8426"
   },
   "outputs": [],
   "source": [
    "# Download COCO val\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
    "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "3e234e05-ee8b-4ad1-b1a4-f6a55d5e4f3d"
   },
   "outputs": [],
   "source": [
    "# Validate YOLOv5s on COCO val\n",
    "!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "bbeeea2b-04fc-4185-aa64-258690495b5a"
   },
   "outputs": [],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data coco128.yaml --weights 'yolov5s.pt' --cfg models/yolov5s.yaml --img 416 --epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Train QuantModel, not pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data coco128.yaml --weights '' --cfg models/yolov5s_quant.yaml --img 416 --epochs 1 --classes 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {}\n",
    "ckpt['model'] = model.state_dict()\n",
    "torch.save(ckpt,\"experiment_models/yolov5s.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Quantized (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please do not forget to add the --cfg for quant models so the code does not break\n",
    "!python train.py --img 416 --batch 16 --epochs 3 --data coco128.yaml --cfg models/yolov5s_quant.yaml --weights experiment_models/yolov5s_quant.pt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train PostQuantization (PTQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please do not forget to add the --cfg for quant models so the code does not break\n",
    "!python train.py --img 416 --batch 16 --epochs 9 --data coco128.yaml --cfg models/yolov5s_quant.yaml --weights yolov5s.pt --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
    "import torch\n",
    "\n",
    "model_pre = torch.hub.load('.',\n",
    "                       'custom',\n",
    "                       'experiment_models/yolov5s.pt',\n",
    "                       source='local',\n",
    "                       classes = 80,\n",
    "                       cfg = \"models/yolov5s.yaml\",\n",
    "                       force_reload=True\n",
    "                      )\n",
    "\n",
    "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
    "results = model_pre(im)  # inference\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in model_pre.state_dict().items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Quantized Model (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMusP4OAxFu6"
   },
   "outputs": [],
   "source": [
    "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('.',\n",
    "                       'custom',\n",
    "                       'experiment_models/yolov5s_quant_pre.pt',\n",
    "                       source='local',\n",
    "                       classes = 80,\n",
    "                       cfg = \"models/yolov5s_quant.yaml\",\n",
    "                       force_reload=True\n",
    "                      )\n",
    "\n",
    "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
    "results = model(im)  # inference\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(im)  # inference\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in model.state_dict().items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(model_pre.state_dict(), strict = False)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Quantized Model (PTQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('.',\n",
    "                       'custom',\n",
    "                       'experiment_models/yolov5s_quant_pre.pt',\n",
    "                       source='local',\n",
    "                       classes = 80,\n",
    "                       cfg = \"models/yolov5s_quant.yaml\",\n",
    "                       force_reload=True\n",
    "                      )\n",
    "\n",
    "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
    "results = model(im)  # inference\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.pandas()\n",
    "df.xyxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying weights for PTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
    "import torch\n",
    "\n",
    "model_quant = torch.hub.load('.',\n",
    "                       'custom',\n",
    "                       'experiment_models/yolov5s_quant.pt',\n",
    "                       source='local',\n",
    "                       classes = 80,\n",
    "                       cfg = \"models/yolov5s_quant.yaml\",\n",
    "                       force_reload=False\n",
    "                      )\n",
    "\n",
    "model = torch.hub.load('.',\n",
    "                       'custom',\n",
    "                       'experiment_models/yolov5s.pt',\n",
    "                       source='local',\n",
    "                       classes = 80,\n",
    "                       cfg = \"models/yolov5s.yaml\",\n",
    "                       force_reload=False\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.model.model[0].conv.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant_state = model_quant.state_dict()\n",
    "model_state = model.state_dict()\n",
    "\n",
    "for key,value in model_state.items():\n",
    "    if key in model_quant_state:\n",
    "        print(key)\n",
    "        model_quant_state[key] = value\n",
    "    else:\n",
    "        print(\"NotFound\",key)\n",
    "        \n",
    "model_quant.load_state_dict(model_quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_quant(im)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant.model.model.model[0].conv.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quant.load_state_dict(model.state_dict(),strict = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "YOLOv5 Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
